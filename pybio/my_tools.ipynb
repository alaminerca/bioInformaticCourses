{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# import packages",
   "id": "90eebe302776ece7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T22:10:21.756652Z",
     "start_time": "2025-01-05T22:10:21.314385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "import Bio \n",
    "from Bio import SeqIO"
   ],
   "id": "b5e20c8d25f9ac68",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Class cotaining usefull methods\n",
    "## Basic DNA Sequence Analysis"
   ],
   "id": "4b4192e757dfd08c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T22:10:51.345993Z",
     "start_time": "2025-01-05T22:10:51.316744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DNAToolkit:\n",
    "    \"\"\"Basic DNA sequence analysis tools\"\"\"\n",
    "    \n",
    "    def __init__(self, sequence):\n",
    "        \"\"\"Initialize with DNA sequence\"\"\"\n",
    "        self.sequence = sequence.upper()  # Standardize input to uppercase\n",
    "        self.valid_bases = set('ATCG')    # Set for O(1) lookup time\n",
    "        \n",
    "    def validate_sequence(self):\n",
    "        \"\"\"Check if sequence contains only valid DNA bases\"\"\"\n",
    "        # all() with generator expression is memory efficient for long sequences\n",
    "        return all(base in self.valid_bases for base in self.sequence)\n",
    "    \n",
    "    def sequence_length(self):\n",
    "        \"\"\"Return sequence length\"\"\"\n",
    "        return len(self.sequence)\n",
    "    \n",
    "    def nucleotide_count(self):\n",
    "        \"\"\"Count occurrences of each nucleotide\"\"\"\n",
    "        # Direct count is more readable than Counter for learning\n",
    "        return {\n",
    "            'A': self.sequence.count('A'),\n",
    "            'T': self.sequence.count('T'),\n",
    "            'G': self.sequence.count('G'),\n",
    "            'C': self.sequence.count('C')\n",
    "        }\n",
    "    \n",
    "    def gc_content(self):\n",
    "        \"\"\"Calculate GC content percentage\"\"\"\n",
    "        counts = self.nucleotide_count()\n",
    "        gc = counts['G'] + counts['C']    # Sum G and C counts\n",
    "        total = sum(counts.values())       # Total bases\n",
    "        return (gc / total) * 100 if total > 0 else 0  # Handle empty sequence\n",
    "    \n",
    "    def find_start_codons(self):\n",
    "        \"\"\"Find all start codon (ATG) positions\"\"\"\n",
    "        positions = []\n",
    "        # Step through sequence with 3-base window\n",
    "        # -2 ensures enough room for complete codon\n",
    "        for i in range(0, len(self.sequence) - 2):\n",
    "            if self.sequence[i:i+3] == 'ATG':  # Start codon check\n",
    "                positions.append(i + 1)         # Convert to 1-based position\n",
    "        return positions\n",
    "    \n",
    "    def find_stop_codons(self):\n",
    "        \"\"\"Find all stop codon (TAA, TAG, TGA) positions\"\"\"\n",
    "        stop_codons = ['TAA', 'TAG', 'TGA']    # All possible stop codons\n",
    "        positions = []\n",
    "        # Same window sliding as start codons\n",
    "        for i in range(0, len(self.sequence) - 2):\n",
    "            if self.sequence[i:i+3] in stop_codons:\n",
    "                positions.append(i + 1)\n",
    "        return positions\n",
    "    \n",
    "    def reverse_complement(self):\n",
    "        \"\"\"Generate reverse complement of sequence\"\"\"\n",
    "        # DNA base pairing rules\n",
    "        complement_dict = {'A': 'T', 'T': 'A', 'G': 'C', 'C': 'G'}\n",
    "        # Build complement then reverse it\n",
    "        complement = ''.join(complement_dict[base] for base in self.sequence)\n",
    "        return complement[::-1]  # Slice notation for reverse"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FASTA File Analysis (Using BioPython)",
   "id": "f597b4efdc22f935"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T22:10:54.397553Z",
     "start_time": "2025-01-05T22:10:54.385553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "class FastaAnalyzer:\n",
    "    \"\"\"FASTA file analysis tools\"\"\"\n",
    "    \n",
    "    def __init__(self, fasta_file):\n",
    "        \"\"\"Initialize with FASTA file path\"\"\"\n",
    "        self.fasta_file = fasta_file\n",
    "        self.records = list(SeqIO.parse(fasta_file, \"fasta\"))\n",
    "        \n",
    "    def count_records(self):\n",
    "        \"\"\"Count number of records in FASTA file\"\"\"\n",
    "        return len(self.records)\n",
    "    \n",
    "    def get_sequence_lengths(self):\n",
    "        \"\"\"Get dictionary of sequence IDs and their lengths\"\"\"\n",
    "        return {record.id: len(record.seq) for record in self.records}\n",
    "    \n",
    "    def find_extreme_sequences(self):\n",
    "        \"\"\"Find longest and shortest sequences\"\"\"\n",
    "        if not self.records:\n",
    "            return None\n",
    "            \n",
    "        lengths = self.get_sequence_lengths()\n",
    "        min_len = min(lengths.values())\n",
    "        max_len = max(lengths.values())\n",
    "        \n",
    "        shortest = [id for id, length in lengths.items() if length == min_len]\n",
    "        longest = [id for id, length in lengths.items() if length == max_len]\n",
    "        \n",
    "        return {\n",
    "            'shortest': {'length': min_len, 'ids': shortest},\n",
    "            'longest': {'length': max_len, 'ids': longest}\n",
    "        }"
   ],
   "id": "4e6a0f07b92c4c78",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ORF Finding",
   "id": "6ea23ab3311ba115"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T22:10:57.748423Z",
     "start_time": "2025-01-05T22:10:57.735076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ORFFinder:\n",
    "    \"\"\"Open Reading Frame analysis tools\"\"\"\n",
    "    \n",
    "    def __init__(self, sequence):\n",
    "        \"\"\"Initialize with DNA sequence\"\"\"\n",
    "        self.sequence = sequence.upper()\n",
    "        \n",
    "    def get_reading_frame(self, frame):\n",
    "        \"\"\"Get sequence in specified reading frame (1, 2, or 3)\"\"\"\n",
    "        # frame-1 converts 1-based frame to 0-based index\n",
    "        return self.sequence[frame-1:]\n",
    "    \n",
    "    def find_orfs_in_frame(self, frame):\n",
    "        \"\"\"Find all ORFs in specified reading frame\"\"\"\n",
    "        seq = self.get_reading_frame(frame)\n",
    "        orfs = []\n",
    "        \n",
    "        i = 0\n",
    "        # -5 ensures room for both start and stop codons\n",
    "        while i < len(seq) - 5:\n",
    "            if seq[i:i+3] == 'ATG':    # Found potential start\n",
    "                j = i + 3              # Move to next codon\n",
    "                while j < len(seq) - 2:\n",
    "                    codon = seq[j:j+3]\n",
    "                    if codon in ['TAA', 'TAG', 'TGA']:  # Found stop\n",
    "                        # Record ORF details with frame-adjusted positions\n",
    "                        orfs.append({\n",
    "                            'start': i + frame,\n",
    "                            'end': j + frame + 2,\n",
    "                            'sequence': seq[i:j+3],\n",
    "                            'length': j + 3 - i\n",
    "                        })\n",
    "                        break\n",
    "                    j += 3  # Move to next codon\n",
    "            i += 3  # Move to next potential start\n",
    "        return orfs\n",
    "    \n",
    "    def find_all_orfs(self):\n",
    "        \"\"\"Find ORFs in all three forward frames\"\"\"\n",
    "        all_orfs = []\n",
    "        # Check each possible reading frame\n",
    "        for frame in [1, 2, 3]:\n",
    "            all_orfs.extend(self.find_orfs_in_frame(frame))\n",
    "        return all_orfs\n",
    "    \n",
    "    def get_longest_orf(self):\n",
    "        \"\"\"Find the longest ORF across all frames\"\"\"\n",
    "        orfs = self.find_all_orfs()\n",
    "        if not orfs:\n",
    "            return None\n",
    "        # Use key function with max for efficiency\n",
    "        return max(orfs, key=lambda x: x['length'])"
   ],
   "id": "959862d0e9421293",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DNA Repeat Finder",
   "id": "7f57cd4ac332b673"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T22:11:07.131291Z",
     "start_time": "2025-01-05T22:11:07.112164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RepeatFinder:\n",
    "    \"\"\"DNA repeat sequence analysis tools\"\"\"\n",
    "    \n",
    "    def __init__(self, sequence):\n",
    "        self.sequence = sequence.upper()\n",
    "        \n",
    "    def find_repeats(self, length):\n",
    "        \"\"\"Find all repeats of specified length\"\"\"\n",
    "        repeats = {}\n",
    "        \n",
    "        # Generate all possible substrings of given length\n",
    "        # +1 ensures last substring is included\n",
    "        for i in range(len(self.sequence) - length + 1):\n",
    "            substring = self.sequence[i:i+length]\n",
    "            count = 0\n",
    "            \n",
    "            # Count all occurrences of current substring\n",
    "            for j in range(len(self.sequence) - length + 1):\n",
    "                if self.sequence[j:j+length] == substring:\n",
    "                    count += 1\n",
    "                    \n",
    "            # Store only if it's a repeat (count > 1)\n",
    "            if count > 1:\n",
    "                repeats[substring] = count\n",
    "                \n",
    "        return repeats\n",
    "    \n",
    "    def most_frequent_repeat(self, length):\n",
    "        \"\"\"Find most frequent repeat of specified length\"\"\"\n",
    "        repeats = self.find_repeats(length)\n",
    "        if not repeats:\n",
    "            return None\n",
    "        \n",
    "        # Find highest count\n",
    "        max_count = max(repeats.values())\n",
    "        # Get all sequences with that count\n",
    "        most_frequent = [seq for seq, count in repeats.items() \n",
    "                        if count == max_count]\n",
    "        \n",
    "        return {\n",
    "            'sequences': most_frequent,\n",
    "            'count': max_count\n",
    "        }"
   ],
   "id": "de772b287de28e73",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Example Usage",
   "id": "2f3ee62b958ba2f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T22:12:54.843284Z",
     "start_time": "2025-01-05T22:12:54.743603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example DNA sequence analysis\n",
    "dna_seq = \"ATGGCCTAAGGCTGATAGATGGCCTAA\"\n",
    "toolkit = DNAToolkit(dna_seq)\n",
    "\n",
    "print(f\"Sequence Length: {toolkit.sequence_length()}\")\n",
    "print(f\"Nucleotide Counts: {toolkit.nucleotide_count()}\")\n",
    "print(f\"GC Content: {toolkit.gc_content():.2f}%\")\n",
    "print(f\"Start Codons at: {toolkit.find_start_codons()}\")\n",
    "print(f\"Stop Codons at: {toolkit.find_stop_codons()}\")\n",
    "print(f\"Reverse Complement: {toolkit.reverse_complement()}\")\n",
    "\n",
    "# Example FASTA analysis\n",
    "fasta_analyzer = FastaAnalyzer(\"dna2.fasta\")\n",
    "print(f\"Number of Records: {fasta_analyzer.count_records()}\")\n",
    "print(f\"Sequence Lengths: {fasta_analyzer.get_sequence_lengths()}\")\n",
    "print(f\"Extreme Sequences: {fasta_analyzer.find_extreme_sequences()}\")\n",
    "\n",
    "# Example ORF finding\n",
    "orf_finder = ORFFinder(dna_seq)\n",
    "print(f\"Longest ORF: {orf_finder.get_longest_orf()}\")\n",
    "\n",
    "# Example repeat finding\n",
    "repeat_finder = RepeatFinder(dna_seq)\n",
    "print(f\"Repeats of length 3: {repeat_finder.find_repeats(3)}\")\n",
    "print(f\"Most frequent repeat: {repeat_finder.most_frequent_repeat(3)}\")"
   ],
   "id": "dc22c0069537b1dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Length: 27\n",
      "Nucleotide Counts: {'A': 8, 'T': 6, 'G': 8, 'C': 5}\n",
      "GC Content: 48.15%\n",
      "Start Codons at: [1, 19]\n",
      "Stop Codons at: [7, 13, 16, 25]\n",
      "Reverse Complement: TTAGGCCATCTATCAGCCTTAGGCCAT\n",
      "Number of Records: 18\n",
      "Sequence Lengths: {'gi|142022655|gb|EQ086233.1|91': 4635, 'gi|142022655|gb|EQ086233.1|304': 1151, 'gi|142022655|gb|EQ086233.1|255': 4894, 'gi|142022655|gb|EQ086233.1|45': 3511, 'gi|142022655|gb|EQ086233.1|396': 4076, 'gi|142022655|gb|EQ086233.1|250': 2867, 'gi|142022655|gb|EQ086233.1|322': 442, 'gi|142022655|gb|EQ086233.1|88': 890, 'gi|142022655|gb|EQ086233.1|594': 967, 'gi|142022655|gb|EQ086233.1|293': 4338, 'gi|142022655|gb|EQ086233.1|75': 1352, 'gi|142022655|gb|EQ086233.1|454': 4564, 'gi|142022655|gb|EQ086233.1|16': 4804, 'gi|142022655|gb|EQ086233.1|584': 964, 'gi|142022655|gb|EQ086233.1|4': 2095, 'gi|142022655|gb|EQ086233.1|277': 1432, 'gi|142022655|gb|EQ086233.1|346': 115, 'gi|142022655|gb|EQ086233.1|527': 2646}\n",
      "Extreme Sequences: {'shortest': {'length': 115, 'ids': ['gi|142022655|gb|EQ086233.1|346']}, 'longest': {'length': 4894, 'ids': ['gi|142022655|gb|EQ086233.1|255']}}\n",
      "Longest ORF: {'start': 1, 'end': 9, 'sequence': 'ATGGCCTAA', 'length': 9}\n",
      "Repeats of length 3: {'ATG': 2, 'TGG': 2, 'GGC': 3, 'GCC': 2, 'CCT': 2, 'CTA': 2, 'TAA': 2, 'GAT': 2}\n",
      "Most frequent repeat: {'sequences': ['GGC'], 'count': 3}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "1a42a2e5646b5ed4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Useful function",
   "id": "ae7bf0dfba1f84c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T20:33:51.955640Z",
     "start_time": "2025-01-06T20:33:51.932541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Create random string\n",
    "def random_string_generator(length):\n",
    "    import random\n",
    "    string = \"\" \n",
    "    desired_length = length\n",
    "    for _ in range(desired_length):\n",
    "        string += random.choice('ACTG')\n",
    "    return string\n",
    "print(random_string_generator(10))"
   ],
   "id": "84bc146559aea660",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCTCGCATCT\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T20:38:10.070745Z",
     "start_time": "2025-01-06T20:38:10.055121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find longoest Common prefix\n",
    "\n",
    "def lcprefix(s1, s2):\n",
    "    i = 0\n",
    "    while i < len(s1) and i < len(s2) and s1[i] == s2[i]:\n",
    "        i += 1\n",
    "    return s1[:i]\n",
    "\n",
    "print(lcprefix(\"acctvfd\", \"acctkfj\"))"
   ],
   "id": "bb88123d31ff4bb5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acct\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Read genome, fasta file\n",
   "id": "9f0c356757243747"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T20:59:38.713029Z",
     "start_time": "2025-01-06T20:59:38.685032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_genome(file):\n",
    "    genome = \"\"\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            if not line[0] == '>':\n",
    "                genome = genome + line.rstrip()\n",
    "    return genome\n",
    "\n",
    "genome = read_genome(\"dna2.fasta\")\n",
    "genome[:100]"
   ],
   "id": "c538b04eafeb0e94",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CTCGCGTTGCAGGCCGGCGTGTCGCGCAACGACGTGTGGGGCCTGACGGGCAGGGAGGATCTCGGCGGCGCCAACTATGCGGTCTTTCGGCTCGAAAGCC'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## count number of bases",
   "id": "45a5c931053a6bef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T21:17:14.385444Z",
     "start_time": "2025-01-06T21:17:14.374441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def count_bases(genome_seq, specific_base = None):\n",
    "    \"\"\"\n",
    "    This function calculate the # of occurence of each base.\n",
    "    :param genome_seq: \n",
    "    :param specific_base: \n",
    "    :return: count_dict:\n",
    "    \"\"\"\n",
    "    # we can also use collections module to do the samething.\n",
    "    count_dict = {}\n",
    "    for base in genome_seq:\n",
    "        if base not in count_dict:\n",
    "            count_dict[base] = 1\n",
    "        else:\n",
    "            count_dict[base] += 1\n",
    "    if specific_base is None:\n",
    "        return count_dict\n",
    "    else:\n",
    "        return count_dict[specific_base]\n",
    "\n",
    "           "
   ],
   "id": "923d8c6efe9ad342",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T21:18:28.116500Z",
     "start_time": "2025-01-06T21:18:28.084426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bases = count_bases(genome)\n",
    "c_count = count_bases(genome, \"C\")"
   ],
   "id": "11055f5b52fa9805",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T21:18:49.581633Z",
     "start_time": "2025-01-06T21:18:49.566312Z"
    }
   },
   "cell_type": "code",
   "source": "print(bases, c_count)",
   "id": "1e5b346657a08947",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 15194, 'T': 7694, 'G': 15161, 'A': 7694} 15194\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c8833908509e4a9c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
